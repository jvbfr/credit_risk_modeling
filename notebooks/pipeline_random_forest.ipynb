{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad95c3cb",
   "metadata": {},
   "source": [
    "## Pipeline Random Forest: Modelo sem boosting mais simples e com maior poder de generalização, bom para testar com quantidade de dados limitada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40ba527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Melhores parâmetros encontrados:\n",
      "{'classifier__n_estimators': 200, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 10, 'classifier__class_weight': None}\n",
      "\n",
      "Melhor AUC na validação cruzada: 0.6380\n",
      "\n",
      "------------------------------ RESULTADO FINAL - MODELO OTIMIZADO ------------------------------\n",
      ">> Performance no Teste Out-of-Time: AUC = 0.6551, KS = 0.2152\n",
      "\n",
      "Comparação com o Baseline (não otimizado):\n",
      "AUC Baseline: 0.6130 | KS Baseline: 0.1720\n",
      "Ganho de AUC: 0.0421\n",
      "Ganho de KS:  0.0432\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import category_encoders as ce\n",
    "from james_stein_custom import _JamesSteinEncoder\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calcular_ks_scipy(y_true: np.ndarray, y_pred_proba: np.ndarray) -> float:\n",
    "    prob_bads = y_pred_proba[y_true == 1]\n",
    "    prob_goods = y_pred_proba[y_true == 0]\n",
    "    if len(prob_bads) == 0 or len(prob_goods) == 0: return 0.0\n",
    "    ks_statistic, p_value = stats.ks_2samp(prob_bads, prob_goods)\n",
    "    return ks_statistic\n",
    "\n",
    "try:\n",
    "    treino_df = pd.read_csv(\"../data/dev/train.csv\", index_col=0)\n",
    "    validacao_df = pd.read_csv(\"../data/dev/val.csv\", index_col=0)\n",
    "    teste_oot_df = pd.read_csv(\"../data/dev/test.csv\", index_col=0)\n",
    "\n",
    "    dev_df = pd.concat([treino_df, validacao_df], ignore_index=True)\n",
    "    \n",
    "    TARGET = 'target'\n",
    "    FEATURES = [col for col in dev_df.columns if col not in [\n",
    "        TARGET, 'data_originacao', 'id_contrato', \"custo_fn\", \"custo_fp\"\n",
    "    ]]\n",
    "\n",
    "    X_dev = dev_df[FEATURES]\n",
    "    y_dev = dev_df[TARGET]\n",
    "    X_oot = teste_oot_df[FEATURES]\n",
    "    y_oot = teste_oot_df[TARGET]\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Problema com os dados: {e}\")\n",
    "    exit()\n",
    "\n",
    "js_cols = ['estado', 'id_varejo']\n",
    "ohe_cols = ['tipo_cliente']\n",
    "target_enc_cols = [col for col in FEATURES if col.endswith('_bin')]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('james_stein', _JamesSteinEncoder(min_samples=100), js_cols),\n",
    "        ('one_hot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, min_frequency=5), ohe_cols),\n",
    "        ('target_encoder', ce.TargetEncoder(), target_enc_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Grid de parâmetros \n",
    "param_dist = {\n",
    "    'classifier__n_estimators': [100, 200, 300, 500],\n",
    "    'classifier__max_depth': [10, 20, 30, None],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2'],\n",
    "    'classifier__class_weight': ['balanced', 'balanced_subsample', None]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# O RandomizedSearchCV testará 10 combinações de parâmetros usando o TimeSeriesSplit como validador\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,  \n",
    "    scoring='roc_auc', \n",
    "    cv=tscv, \n",
    "    n_jobs=-1, \n",
    "    random_state=42,\n",
    "    verbose=2 \n",
    ")\n",
    "\n",
    "random_search.fit(X_dev, y_dev)\n",
    "\n",
    "print(\"Melhores parâmetros encontrados:\")\n",
    "print(random_search.best_params_)\n",
    "print(f\"\\nMelhor AUC na validação cruzada: {random_search.best_score_:.4f}\")\n",
    "\n",
    "y_oot_pred_proba_tuned = random_search.predict_proba(X_oot)[:, 1]\n",
    "\n",
    "auc_oot_tuned = roc_auc_score(y_oot, y_oot_pred_proba_tuned)\n",
    "ks_oot_tuned = calcular_ks_scipy(y_oot.values, y_oot_pred_proba_tuned)\n",
    "\n",
    "print(\"\\n\" + \"---\" * 10 + \" RESULTADO FINAL - MODELO OTIMIZADO \" + \"---\" * 10)\n",
    "print(f\">> Performance no Teste Out-of-Time: AUC = {auc_oot_tuned:.4f}, KS = {ks_oot_tuned:.4f}\")\n",
    "\n",
    "print(\"\\nComparação com o Baseline (não otimizado):\")\n",
    "print(\"AUC Baseline: 0.6130 | KS Baseline: 0.1720\") # -> achei anteriormente\n",
    "print(f\"Ganho de AUC: {(auc_oot_tuned - 0.6130):.4f}\")\n",
    "print(f\"Ganho de KS:  {(ks_oot_tuned - 0.1720):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpd30",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
